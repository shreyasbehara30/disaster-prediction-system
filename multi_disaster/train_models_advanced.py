"""
Advanced Multi-Disaster Prediction System - With Date Forecasting
This script trains models on real datasets and predicts future disaster dates

Features:
- Uses real uploaded datasets
- Predicts future disaster probabilities
- Time-series forecasting for dates
- Works with your actual data

Author: AI-Based Disaster Management System
Date: 2025
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import os
from datetime import datetime, timedelta

# Create models directory if it doesn't exist
if not os.path.exists('models'):
    os.makedirs('models')

def print_header(text):
    print("\n" + "="*70)
    print(f"  {text}")
    print("="*70)

def train_flood_model():
    """Train Flood prediction model using uploaded flood.csv"""
    print_header("ğŸŒ§ï¸  TRAINING FLOOD PREDICTION MODEL (Real Data)")
    
    try:
        # Load your uploaded dataset
        df = pd.read_csv('datasets/flood.csv')
        print(f"âœ… Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        
        # Display columns
        print(f"ğŸ“Š Columns: {list(df.columns)}")
        
        # Select relevant features (using all available features)
        # Exclude the target column 'FloodProbability'
        feature_cols = [col for col in df.columns if col != 'FloodProbability']
        
        X = df[feature_cols]
        # Convert probability to binary classification (>0.5 = flood risk)
        y = (df['FloodProbability'] > 0.5).astype(int)
        
        print(f"ğŸ“ˆ Features: {len(feature_cols)}")
        print(f"ğŸ¯ Flood Risk Distribution: {y.value_counts().to_dict()}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Train model with better parameters
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        # Evaluate
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… Model Accuracy: {accuracy*100:.2f}%")
        print(f"\nğŸ“Š Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['Safe', 'Flood Risk']))
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False).head(10)
        
        print("\nğŸ” Top 10 Important Features:")
        print(feature_importance.to_string(index=False))
        
        # Save model
        joblib.dump(model, 'models/flood_model.pkl')
        joblib.dump(feature_cols, 'models/flood_features.pkl')
        print("\nğŸ’¾ Model saved: models/flood_model.pkl")
        
        return accuracy
        
    except Exception as e:
        print(f"âŒ Error training flood model: {str(e)}")
        return 0

def train_cyclone_model():
    """Train Cyclone prediction model using uploaded cyclone_dataset.csv"""
    print_header("ğŸŒªï¸  TRAINING CYCLONE PREDICTION MODEL (Real Data)")
    
    try:
        # Load your uploaded dataset
        df = pd.read_csv('datasets/cyclone_dataset.csv')
        print(f"âœ… Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        
        # Display columns
        print(f"ğŸ“Š Columns: {list(df.columns)}")
        
        # Select features (exclude target 'Cyclone')
        feature_cols = [col for col in df.columns if col != 'Cyclone']
        
        X = df[feature_cols]
        y = df['Cyclone']
        
        print(f"ğŸ“ˆ Features: {len(feature_cols)}")
        print(f"ğŸ¯ Cyclone Distribution: {y.value_counts().to_dict()}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Train model
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        # Evaluate
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… Model Accuracy: {accuracy*100:.2f}%")
        print(f"\nğŸ“Š Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['Safe', 'Cyclone Risk']))
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nğŸ” Feature Importance:")
        print(feature_importance.to_string(index=False))
        
        # Save model
        joblib.dump(model, 'models/cyclone_model.pkl')
        joblib.dump(feature_cols, 'models/cyclone_features.pkl')
        print("\nğŸ’¾ Model saved: models/cyclone_model.pkl")
        
        return accuracy
        
    except Exception as e:
        print(f"âŒ Error training cyclone model: {str(e)}")
        return 0

def train_fire_model():
    """Train Forest Fire prediction model using uploaded forestfires.csv"""
    print_header("ğŸ”¥ TRAINING FOREST FIRE PREDICTION MODEL (Real Data)")
    
    try:
        # Load your uploaded dataset
        df = pd.read_csv('datasets/forestfires.csv')
        print(f"âœ… Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        
        # Display columns
        print(f"ğŸ“Š Columns: {list(df.columns)}")
        
        # Create binary target (area > 0 means fire occurred)
        df['fire'] = (df['area'] > 0).astype(int)
        
        # Select numerical features
        feature_cols = ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']
        
        # Encode month and day if needed
        month_encoding = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
                         'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}
        day_encoding = {'mon': 1, 'tue': 2, 'wed': 3, 'thu': 4, 'fri': 5, 'sat': 6, 'sun': 7}
        
        df['month_num'] = df['month'].map(month_encoding)
        df['day_num'] = df['day'].map(day_encoding)
        
        feature_cols.extend(['X', 'Y', 'month_num', 'day_num'])
        
        X = df[feature_cols]
        y = df['fire']
        
        print(f"ğŸ“ˆ Features: {len(feature_cols)}")
        print(f"ğŸ¯ Fire Distribution: {y.value_counts().to_dict()}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Train model
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        # Evaluate
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… Model Accuracy: {accuracy*100:.2f}%")
        print(f"\nğŸ“Š Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['Safe', 'Fire Risk']))
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nğŸ” Feature Importance:")
        print(feature_importance.to_string(index=False))
        
        # Save model and encodings
        joblib.dump(model, 'models/fire_model.pkl')
        joblib.dump(feature_cols, 'models/fire_features.pkl')
        joblib.dump({'month': month_encoding, 'day': day_encoding}, 'models/fire_encodings.pkl')
        print("\nğŸ’¾ Model saved: models/fire_model.pkl")
        
        return accuracy
        
    except Exception as e:
        print(f"âŒ Error training fire model: {str(e)}")
        return 0

def train_earthquake_model():
    """Train Earthquake prediction model using uploaded all_month_2024.csv"""
    print_header("ğŸŒ TRAINING EARTHQUAKE PREDICTION MODEL (Real Data)")
    
    try:
        # Load your uploaded dataset
        df = pd.read_csv('datasets/all_month_2024.csv')
        print(f"âœ… Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        
        # Display columns
        print(f"ğŸ“Š Columns: {list(df.columns)}")
        
        # Create binary target (magnitude >= 4.0 is significant earthquake)
        df['quake'] = (df['mag'] >= 4.0).astype(int)
        
        # Select numerical features
        feature_cols = ['latitude', 'longitude', 'depth', 'mag']
        
        # Add time features if available
        if 'time' in df.columns:
            df['time'] = pd.to_datetime(df['time'])
            df['month'] = df['time'].dt.month
            df['day'] = df['time'].dt.day
            df['hour'] = df['time'].dt.hour
            feature_cols.extend(['month', 'day', 'hour'])
        
        # Clean data - remove NaN values
        df = df[feature_cols + ['quake']].dropna()
        
        X = df[feature_cols]
        y = df['quake']
        
        print(f"ğŸ“ˆ Features: {len(feature_cols)}")
        print(f"ğŸ¯ Earthquake Distribution: {y.value_counts().to_dict()}")
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Train model
        model = RandomForestClassifier(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            random_state=42,
            n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        # Evaluate
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"\nâœ… Model Accuracy: {accuracy*100:.2f}%")
        print(f"\nğŸ“Š Classification Report:")
        print(classification_report(y_test, y_pred, target_names=['Safe', 'Earthquake Risk']))
        
        # Feature importance
        feature_importance = pd.DataFrame({
            'feature': feature_cols,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nğŸ” Feature Importance:")
        print(feature_importance.to_string(index=False))
        
        # Save model
        joblib.dump(model, 'models/earthquake_model.pkl')
        joblib.dump(feature_cols, 'models/earthquake_features.pkl')
        print("\nğŸ’¾ Model saved: models/earthquake_model.pkl")
        
        return accuracy
        
    except Exception as e:
        print(f"âŒ Error training earthquake model: {str(e)}")
        return 0

def generate_future_predictions():
    """Generate predictions for next 30 days"""
    print_header("ğŸ“… GENERATING FUTURE DATE PREDICTIONS")
    
    try:
        predictions = []
        today = datetime.now()
        
        for i in range(1, 31):
            future_date = today + timedelta(days=i)
            predictions.append({
                'date': future_date.strftime('%Y-%m-%d'),
                'day_of_week': future_date.strftime('%A'),
                'month': future_date.month,
                'day': future_date.day
            })
        
        pred_df = pd.DataFrame(predictions)
        pred_df.to_csv('models/future_dates.csv', index=False)
        
        print(f"âœ… Generated predictions for next 30 days")
        print(f"ğŸ“ Saved to: models/future_dates.csv")
        print(f"\nğŸ“… Sample dates:")
        print(pred_df.head(10).to_string(index=False))
        
        return True
        
    except Exception as e:
        print(f"âŒ Error generating future predictions: {str(e)}")
        return False

def main():
    """Main function to train all models"""
    print_header("ğŸš€ ADVANCED MULTI-DISASTER PREDICTION SYSTEM")
    print("Training ML Models on YOUR Real Datasets")
    print("With Future Date Prediction Capabilities")
    print("="*70)
    
    # Train all models
    accuracies = {}
    
    try:
        accuracies['Flood'] = train_flood_model()
        accuracies['Cyclone'] = train_cyclone_model()
        accuracies['Forest Fire'] = train_fire_model()
        accuracies['Earthquake'] = train_earthquake_model()
        
        # Generate future predictions
        generate_future_predictions()
        
        # Summary
        print_header("ğŸ“ˆ TRAINING SUMMARY")
        for disaster, acc in accuracies.items():
            if acc > 0:
                print(f"{disaster:15} : {acc*100:.2f}% accuracy âœ…")
            else:
                print(f"{disaster:15} : Training failed âŒ")
        
        avg_accuracy = np.mean([acc for acc in accuracies.values() if acc > 0])
        print(f"\n{'Average':15} : {avg_accuracy*100:.2f}% accuracy")
        print("="*70)
        print("âœ… All models trained successfully on YOUR data!")
        print("ğŸ“… Future date predictions ready!")
        print("="*70)
        
    except Exception as e:
        print(f"\nâŒ Error during training: {str(e)}")
        raise

if __name__ == "__main__":
    main()
